{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUms_6O08JIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd8pSYeV9NrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_name = \"FrozenLake-v0\"\n",
        "\n",
        "env = gym.make(env_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuADFbHg9nvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def short_description(env = env, demo = True, demo_steps = 5):\n",
        "  n_states = env.env.observation_space.n\n",
        "  n_actions = env.env.action_space.n\n",
        "\n",
        "  print(\"This environnement {} has {} possible states and {} possible actions\".format(env_name, n_states, n_actions))\n",
        "  \n",
        "  if demo:\n",
        "    observation = env.reset()\n",
        "    for _ in range(demo_steps):\n",
        "      env.render()\n",
        "      action = env.action_space.sample() \n",
        "      observation, _, done, _ = env.step(action)\n",
        "\n",
        "      if done:\n",
        "        observation = env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExWqE_9V9tI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "f0359c18-7170-4c92-d120-45718fd0fcb9"
      },
      "source": [
        "short_description(env)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This environnement FrozenLake-v0 has 16 possible states and 4 possible actions\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Right)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "S\u001b[41mF\u001b[0mFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B5FGpp6_q8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def q_learning_train(env = env, n_episodes = 2, n_steps_per_episode = 5, gamma = 0.99, lr0 = 1, lambda_ = 0.05, min_eps = 0.01, pretrained_q_table = None):\n",
        "  epsilon0 = 1\n",
        "  \n",
        "  n_states = env.observation_space.n\n",
        "  n_actions = env.action_space.n\n",
        "  \n",
        "  q_table = np.zeros((n_states, n_actions))\n",
        "  \n",
        "  if pretrained_q_table:\n",
        "    q_table = pretrained_q_table.copy()\n",
        "    \n",
        "  total_rewards = []\n",
        "  \n",
        "  for episode in range(1, n_episodes + 1):\n",
        "    total_reward = 0\n",
        "    obs = env.reset()\n",
        "    epsilon = max(epsilon0 - lambda_*episode, min_eps)\n",
        "    lr = lr0/episode\n",
        "    \n",
        "    for episode_step in range(n_steps_per_episode):\n",
        "      u = np.random.rand()\n",
        "      \n",
        "      if u<epsilon:\n",
        "        action = env.action_space.sample()\n",
        "        \n",
        "      else:\n",
        "        action = q_table[obs, :].argmax()\n",
        "      \n",
        "      obs2, reward, done, _ = env.step(action)\n",
        "      \n",
        "      total_reward += reward\n",
        "      \n",
        "      if done:\n",
        "        discounted_reward = reward\n",
        "        \n",
        "      else:\n",
        "        discounted_reward = reward + gamma * max(q_table[obs2, :])\n",
        "      \n",
        "      q_table[obs, action] = (1-lr)*q_table[obs, action] + lr*discounted_reward\n",
        "      \n",
        "      if done:\n",
        "        break\n",
        "        \n",
        "      obs = obs2\n",
        "    total_rewards.append(total_reward)\n",
        "    if episode % 10000 == 0:\n",
        "      print(\"episode \", episode)\n",
        "  \n",
        "  return q_table, total_rewards    \n",
        "      \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "untXKI6LGMsT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "b017090c-5349-4b60-da46-7a66b2130bbb"
      },
      "source": [
        "n_episodes = 1000000\n",
        "n_steps_per_episode = 1000\n",
        "lr0 = 100\n",
        "\n",
        "q_table, total_rewards = q_learning_train(\n",
        "    env = env, \n",
        "    n_episodes = n_episodes, \n",
        "    n_steps_per_episode = n_steps_per_episode, \n",
        "    gamma = 0.99, \n",
        "    lr0 = lr0, \n",
        "    pretrained_q_table = None\n",
        ")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode  10000\n",
            "episode  20000\n",
            "episode  30000\n",
            "episode  40000\n",
            "episode  50000\n",
            "episode  60000\n",
            "episode  70000\n",
            "episode  80000\n",
            "episode  90000\n",
            "episode  100000\n",
            "episode  110000\n",
            "episode  120000\n",
            "episode  130000\n",
            "episode  140000\n",
            "episode  150000\n",
            "episode  160000\n",
            "episode  170000\n",
            "episode  180000\n",
            "episode  190000\n",
            "episode  200000\n",
            "episode  210000\n",
            "episode  220000\n",
            "episode  230000\n",
            "episode  240000\n",
            "episode  250000\n",
            "episode  260000\n",
            "episode  270000\n",
            "episode  280000\n",
            "episode  290000\n",
            "episode  300000\n",
            "episode  310000\n",
            "episode  320000\n",
            "episode  330000\n",
            "episode  340000\n",
            "episode  350000\n",
            "episode  360000\n",
            "episode  370000\n",
            "episode  380000\n",
            "episode  390000\n",
            "episode  400000\n",
            "episode  410000\n",
            "episode  420000\n",
            "episode  430000\n",
            "episode  440000\n",
            "episode  450000\n",
            "episode  460000\n",
            "episode  470000\n",
            "episode  480000\n",
            "episode  490000\n",
            "episode  500000\n",
            "episode  510000\n",
            "episode  520000\n",
            "episode  530000\n",
            "episode  540000\n",
            "episode  550000\n",
            "episode  560000\n",
            "episode  570000\n",
            "episode  580000\n",
            "episode  590000\n",
            "episode  600000\n",
            "episode  610000\n",
            "episode  620000\n",
            "episode  630000\n",
            "episode  640000\n",
            "episode  650000\n",
            "episode  660000\n",
            "episode  670000\n",
            "episode  680000\n",
            "episode  690000\n",
            "episode  700000\n",
            "episode  710000\n",
            "episode  720000\n",
            "episode  730000\n",
            "episode  740000\n",
            "episode  750000\n",
            "episode  760000\n",
            "episode  770000\n",
            "episode  780000\n",
            "episode  790000\n",
            "episode  800000\n",
            "episode  810000\n",
            "episode  820000\n",
            "episode  830000\n",
            "episode  840000\n",
            "episode  850000\n",
            "episode  860000\n",
            "episode  870000\n",
            "episode  880000\n",
            "episode  890000\n",
            "episode  900000\n",
            "episode  910000\n",
            "episode  920000\n",
            "episode  930000\n",
            "episode  940000\n",
            "episode  950000\n",
            "episode  960000\n",
            "episode  970000\n",
            "episode  980000\n",
            "episode  990000\n",
            "episode  1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPGr7P_rKUaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(env = env, q_table = q_table):\n",
        "  obs = env.reset()\n",
        "  \n",
        "  env.render()\n",
        "  for i in range(1):\n",
        "    print(\"episode \", i)\n",
        "    for _ in range(100):\n",
        "      obs, reward, done, _ = env.step(q_table[obs, :].argmax())\n",
        "      env.render()\n",
        "      if done:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr0VR88IK-Au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4073ea5e-822b-42b6-f7e6-aa9697fb38d7"
      },
      "source": [
        "test()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "episode  0\n",
            "  (Left)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "\u001b[41mF\u001b[0mFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "\u001b[41mH\u001b[0mFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6_nV8qrOjKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}